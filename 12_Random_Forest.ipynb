{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: V09_Bootstrap_assignment_modified (23 March 2022 --- YADAV)\n",
    "\n",
    "                    APPLIED ROOTS VARIFICATION HAS TO BE DONE\n",
    "                                                    -- YADAV(23 MARCH 2022)\n",
    "\n",
    "#### NOTE: V08_Bootstrap_assignment_modified (21 March 2022 --- YADAV)\n",
    "\n",
    "1. TASK2, Task3 and CI are executed. In the next version(V09), all the redundancy will be deleted. \n",
    "\n",
    "\n",
    "\n",
    "#### NOTE: V07_Bootstrap_assignment_modified (12 March 2022 --- YADAV)\n",
    "\n",
    "1. Pseudocode of MSE and OOBS with many drafts, next version V08 will have the limited drafts. \n",
    "\n",
    "#### NOTE: V06_Bootstrap_assignment_modified (02 March 2022 --- YADAV)\n",
    "\n",
    "1. V05 and V06 hasn't completed the task 2 properly. So, for better pseudo work, creating V07. \n",
    "\n",
    "\n",
    "#### NOTE: V05_Bootstrap_assignment_modified (28Feb 2022 --- YADAV)\n",
    "\n",
    "1. V05 has done with MSE calculation, there are alot draft. So, next version will have only MSE and CI of task and OOB score will be calculated.\n",
    "\n",
    "\n",
    "\n",
    "#### NOTE: V04_Bootstrap_assignment_modified (27Feb 2022 --- YADAV)\n",
    "1. Task 01, OOB score has been caluculated. In the next version V05, will be on task 2. Code drafts for OOB score will be removed in the next version of it. \n",
    "\n",
    "\n",
    "#### NOTE: V03_Bootstrap_assignment_modified (23 Feb 2022 --- YADAV)\n",
    "\n",
    "1. Taks 2, has been modified. Each boston data has been iterated with column sampling. However, in this I just considered only 4 iteration for simplifications rather than 30 iteration.\n",
    "2. So, each boston data will have 4 samples, from these 4 samples the median has been calculated.\n",
    "3. V04 will have updates and redundant code will be removed for easy understading.\n",
    "\n",
    "\n",
    "\n",
    "#### NOTE: V02_Bootstrap_assignment_modified (03 Feb 2022 --- YADAV)\n",
    "\n",
    "1. Creating V03 for simplication, taking out redundant one. But, if you need to see detail understand of it, come back to V02 to understand. \n",
    "2. V03 is due, coding starting after 14 days, it's due to thesis work, didn't do coding.\n",
    "\n",
    "\n",
    "\n",
    "#### NOTE: V01_Bootstrap_assignment_modified (26 JAN 2022 --- YADAV)\n",
    "\n",
    "1. V01 function task 1 encoded with final sample data, final target data in one function it self. However, according to the applied roots requirement, the function has to encode until as follows # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "2. So, in the next version (v02) will followed that requirement. \n",
    "3. The draft work is not erasing, since there are many important coding has done to understand the assignment. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes\n",
    "\n",
    "* <font color='red'><b> Note - While selecting the random 60% datapoints from the whole data, make sure that the selected datapoints are all exclusive, repetition is not allowed. </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6rShd89t552"
   },
   "source": [
    "## <font color='red'><b>A few key points</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdgTUXTouHEd"
   },
   "source": [
    "* Remember that the datapoints used for calculating MSE score contain some datapoints that were initially used while training the base learners (the 60% sampling). This makes these datapoints partially seen (i.e. the datapoints used for calculating the MSE score are a mixture of seen and unseen data).\n",
    "Whereas, the datapoints used for calculating OOB score have only the unseen data. This makes these datapoints completely unseen and therefore appropriate for testing the model's performance on unseen data.\n",
    "\n",
    "* Given the information above, if your logic is correct, the calculated MSE score should be less than the OOB score.\n",
    "\n",
    "* The MSE score must lie between 0 and 10.\n",
    "* The OOB score must lie between 10 and 35.\n",
    "\n",
    "* The difference between the left nad right confidence-interval values must not be more than 10. Make sure this is true for both MSE and OOB confidence-interval values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/OfcFrUP.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random choice: https://note.nkmk.me/en/python-random-choice-sample-choices/#:~:text=To%20get%20random%20elements%20from,list%20of%20multiple%20random%20elements.\n",
    "#random length : https://www.codegrepper.com/code-examples/python/np.random.choice+replace\n",
    "#column indices : https://stackoverflow.com/questions/43506766/randomly-select-from-numpy-array\n",
    "#randint: https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html\n",
    "#column slices: https://stackoverflow.com/questions/903853/how-do-you-extract-a-column-from-a-multi-dimensional-array\n",
    "#understanding slices: https://stackoverflow.com/questions/509211/understanding-slice-notation\n",
    "\n",
    "# PROGRESS 2 : (WORK ON PROGRESS-- YADAV 03 FEB 2022) -- FUNCTION HAS INCLUDE ACCORDING TO PSEUDO CODE\n",
    " \n",
    "\n",
    "\n",
    "def generating_samples(input_data, target_data):\n",
    "\n",
    "    '''In this function, we will write code for generating 30 samples '''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples \n",
    "    \n",
    "    subset_size_1=int(0.6 *len(input_data)) # applied roots requirements # \n",
    "    #print(\"len of subset_size_1: \",subset_size_1)\n",
    "    select_rows=np.random.choice(range(len(input_data)),subset_size_1,replace=False) # random row indices. replace=False, repetation not allowed\n",
    "    #print(\"Indices of select_rows: \\n\",select_rows)\n",
    "    \n",
    "    subset_size_2=int(0.67*len(select_rows)) # applied roots requirements\n",
    "    #print(\"len of subset_size_2: \",subset_size_2)\n",
    "    replace_rows=np.random.choice(range(len(select_rows)),subset_size_2,replace=True) #random row indices, repetation is allowed\n",
    "    #print(\"Indices of replace_rows: \\n\",replace_rows)\n",
    "    \n",
    "    subset_size_3=np.random.randint(3,13) # applied roots requirements # generating columns inbetween 3 to 13\n",
    "    #print(\"len of subset_size_3: \",subset_size_3)\n",
    "    \n",
    "    select_columns=np.random.choice(range(len(input_data[:][0])),subset_size_3,replace=False) #random column indices\n",
    "    #select_columns=range(subset_size_3)\n",
    "    #print(\"select_columns: \",select_columns)\n",
    "    \n",
    "\n",
    "    j=[]\n",
    "    for s in select_rows:\n",
    "        #print(s)\n",
    "        for k in select_columns:\n",
    "            #print(k)\n",
    "            i=input_data[s,k]\n",
    "            #print(i)\n",
    "            j.append(i)\n",
    "    sample_data=np.array(list(j)).reshape(len(select_rows),len(select_columns))\n",
    "    target_sample_data=target_data[select_rows]\n",
    "    #print(\"target_sample_data: \",len(target_sample_data))\n",
    "    #print(\"target_sample_data: \",target_sample_data)\n",
    "    \n",
    "    #replicating data\n",
    "    \n",
    "    replicate_sample_data=sample_data[replace_rows] # replacing rows indices from sample data\n",
    "    target_of_replicated_sample_data=target_sample_data[replace_rows]  # replacing rows indices from target_sample_data\n",
    "    #print(\"target_of_replicated_sample_data: \",len(target_of_replicated_sample_data))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #concatinating data\n",
    "    \n",
    "    final_sample_data=np.vstack((sample_data,replicate_sample_data)) #final sample data\n",
    "    #print(\"final_sample_data: \",final_sample_data)\n",
    "    #print(\"final_sample_data: \",len(final_sample_data))\n",
    "    final_target_data=np.vstack((target_sample_data.reshape(-1,1),target_of_replicated_sample_data.reshape(-1,1))) #final target data\n",
    "    #print(\"final_target_data: \",final_target_data)\n",
    "    #print(\"final_target_data: \",len(final_target_data))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return final_sample_data,final_target_data,select_rows,select_columns\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "    #note please return as lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/OfcFrUP.jpg/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  506 \n",
      "b:  506 \n",
      "c:  303 \n",
      "d:  8\n"
     ]
    }
   ],
   "source": [
    "# a -- > sample_data\n",
    "# b -- > target_data\n",
    "# c -- > select_rows\n",
    "# d -- > select_columns\n",
    "\n",
    "a,b,c,d=generating_samples(x,y)\n",
    "print(\"a: \",len(a),\"\\nb: \",len(b),\"\\nc: \",len(c),\"\\nd: \",len(d))\n",
    "\n",
    "\n",
    "#print(len(c))\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set([str(i) for i in a]) -- yadav 03 feb 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(0,30):\n",
    "    a,b,c,d=generating_samples(x,y)\n",
    "    #print(a)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [],
   "source": [
    "#def grader_30(a):\n",
    " #   assert(len(a)==30 and len(a[0])==506)\n",
    "  #  return True\n",
    "#grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "506\n",
      "303\n",
      "6\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "\n",
      "len of x:  506\n",
      "\n",
      "list_selected_columns:  [array([ 5,  3,  6,  0, 10]), array([ 9,  3,  7,  5, 10,  6, 11,  8,  2,  0]), array([11,  4,  0]), array([ 6,  0,  8,  4, 11,  5,  7, 12,  2,  1,  3, 10]), array([ 8, 12,  7,  2, 11,  4,  0]), array([10,  1,  3,  2]), array([10,  0,  3,  4,  7,  6,  5,  9, 11,  8, 12]), array([ 9, 10, 12,  0,  4,  8]), array([4, 0, 7]), array([ 1,  9,  7,  2, 10, 11,  4]), array([ 9,  1,  0,  6,  7, 12, 10,  3]), array([10,  0,  7, 12]), array([ 3,  9, 11,  7,  5,  8, 10,  2,  4]), array([ 9,  6, 10,  4,  2,  8,  0,  3, 11,  5,  7]), array([ 0, 11, 10,  1]), array([ 5, 10,  0, 12,  4]), array([0, 8, 6, 5]), array([ 6,  3,  1,  8, 12,  7]), array([12,  2,  1,  4,  7,  0, 11,  3,  9,  8,  5]), array([ 1,  7, 11, 12,  3]), array([ 4, 12, 11,  7, 10,  6,  8,  5]), array([ 4,  9,  1,  0, 10,  7,  8,  6, 12,  3,  2]), array([ 3,  5,  4,  8, 12,  0, 10]), array([9, 0, 5]), array([ 7,  3,  0,  6, 10,  1,  2,  5, 11, 12]), array([ 8,  2,  4,  3,  0, 11,  6,  7]), array([ 6,  1,  2, 12,  5]), array([10,  8,  4,  6]), array([ 8,  2,  1,  5,  7, 12,  4]), array([12, 10,  1,  3, 11,  5])]\n",
      "\n",
      "list_selected_columns:  [ 5  3  6  0 10]\n",
      "[6.575e+00 0.000e+00 6.520e+01 6.320e-03 1.530e+01]\n",
      "\n",
      "len of list_selected_columns:  5\n",
      "21.6\n"
     ]
    }
   ],
   "source": [
    "# THIS WILL MAKE YOU TO UNDERSTAND THE TASK 2 \n",
    "# THE IMPLEMENTATION OF TASK 2 WILL BE NEXT STEP \n",
    "\n",
    "print(len(a)) # sample data\n",
    "print(len(b)) # target data\n",
    "print(len(c)) # rows\n",
    "print(len(d)) # columns\n",
    "\n",
    "print(len(list_input_data))\n",
    "print(len(list_output_data))\n",
    "print(len(list_selected_row))\n",
    "print(len(list_selected_columns))\n",
    "\n",
    "print(\"\\nlen of x: \",len(x))\n",
    "#print(list_selected_row)\n",
    "print(\"\\nlist_selected_columns: \",list_selected_columns)\n",
    "print(\"\\nlist_selected_columns: \",list_selected_columns[0]) # iteration #checking \n",
    "\n",
    "#print(x[0]) # boston data with selected row for verification with limited column number\n",
    "print(x[0][list_selected_columns[0]]) # boston data with row and selected columns ; selected columns range depend on applied roots requirements\n",
    "print(\"\\nlen of list_selected_columns: \",len(x[0][list_selected_columns[0]])) # len of boston data with selected columns\n",
    "\n",
    "print(y[1]) # targeted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "len X:  506\n",
      "list_of_all_models:  [DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n"
     ]
    }
   ],
   "source": [
    "# MODIFYING THE IMPLEMENTATED CODE BASED ON REFERENCE -- 26 FEB 2022\n",
    "\n",
    "list_of_all_models=[]\n",
    "\n",
    "\n",
    "for t,(X,Y) in enumerate (zip(list_input_data, list_output_data)): # Applied Roots requirements is 30 iterations \n",
    "    #print(t) # checking the length # applied roots requirements 30 iterations\n",
    "    #print(X[0]) \n",
    "    print(\"len X: \",len(X)) # each iteration will have the length of 506 rows\n",
    "    \n",
    "    #print(X) \n",
    "    #print(Y)\n",
    "    #print(\"len Y: \",len(Y))\n",
    "    \n",
    "\n",
    "    model=DecisionTreeRegressor(max_depth=None)\n",
    "    model=model.fit(X,Y)\n",
    "    #print(model) # checking the length of the model. Applied Roots requirements is 30 iterations \n",
    "    list_of_all_models.append(model)\n",
    "\n",
    "print(\"list_of_all_models: \",list_of_all_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len Y_pred:  506\n"
     ]
    }
   ],
   "source": [
    "Y_pred=[] # creating a list to take the median value from the array_of_Y\n",
    "for data_point in x: # x is the boston data  x= 506 x 13\n",
    "    #print(data_point) # datapoint is the rows of boston data. each data point will have 16 columns\n",
    "    \n",
    "    array_of_Y=[] # creating a list to predict the boston data with each row and column sampling with applied roots requirements\n",
    "    \n",
    "    for i in range(len(list_of_all_models)): # this should be same as number models --- applied roots requirements (30 iterations)\n",
    "        #print(data_point[list_selected_columns[i]])    #  boston data with selected columns such as with column sampling(trained one - task 1)\n",
    "        \n",
    "        # for each boston data(data_point), you get given (applied roots requirements =30 ) data points\n",
    "        array_of_Y.append(list_of_all_models[i].predict(data_point[list_selected_columns[i]].reshape(1,-1))) # simple understanding purpose only {model.predict(x)} \n",
    "    #print(array_of_Y)\n",
    "    \n",
    "    #from the array of data points , taking the median/mean (because each data point has 30 iterations/samples)\n",
    "    Y_pred.append(np.median(np.array(array_of_Y).reshape(1,-1)))\n",
    "\n",
    "    \n",
    "#LIST_OF_ALL_MODELS=list_of_all_models\n",
    "#print(LIST_OF_ALL_MODELS)\n",
    "\n",
    "y_pred=np.array(Y_pred)\n",
    "#print(\"\\nY_pred: \\n\",Y_pred)\n",
    "print(\"\\nlen Y_pred: \",len(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045285735469834554\n"
     ]
    }
   ],
   "source": [
    "#calculating MSE\n",
    "\n",
    "MSE=mean_squared_error(y,y_pred)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "[301 185 374 438 310 274  14  30 484 229 328 469 277 101 281 248 421   7\n",
      " 416  68 481 470  12 152  24 415 245 102 482 390  26 476 393 173  28 490\n",
      " 353 139 499 318 125 219 207 264  10 167 362 383 385 251 321  87  90 249\n",
      " 466 345 108 351 186 395 323 208 366 294 297 394 341 433 225 355  76  31\n",
      "  74 302 477 322  34 160 352 319 329  22 468 447 176 369   5  48 200 406\n",
      " 361 182 305 290 379 343 444 104  71 156 372 171 134  96  82 387  57 400\n",
      " 214 123  41 260 494 120 216 397 483   0 286 464  42 210 432  40 169 103\n",
      " 326 133 259 131 473 194 188 371 206 327 158  72 202 404 417 479 114  37\n",
      " 495 365 342  97  79  55 347 357  84 279 196  11 276   4  77 211 187 224\n",
      " 267 360 324 346 266 475 337 107 370 306 271 246  85  73 348 313  23 386\n",
      "  29 287 309 298  51 311 292 488 178 128 166 137   6 478 500  60 316 420\n",
      " 278  25 122 459 401 221  67 288 106 391   8 235 381  52 209 419 449 124\n",
      " 472 339 424 255 354 375 256 498  88 350  86 340 272  61 504 121  27 431\n",
      "  78 232 117 349 373 410  49 356  92 183 480 231 257 314 163 457 175  36\n",
      " 184 439 458 463  70 460 296 172 127 222 269 436  46 461 145 384 452 378\n",
      " 135 105  89 240 283  15  19 332  93 126 223 119 412  98 201 405  64  80\n",
      "  83 112 242 132 198 179 111  99 165  95 285 268  50 396  47]\n"
     ]
    }
   ],
   "source": [
    "#print(list_selected_row) # 4 iteraions in this case with\n",
    "print(len(list_selected_row[1])) # len is 303\n",
    "print((list_selected_row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Fog_6DNdS-h_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_SCORE:  12.991484931206125\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "#print(y_pred)\n",
    "for i,point in enumerate (x): # boston data \n",
    "    #print(i)\n",
    "    #print(point)\n",
    "    #print(len(point))\n",
    "    models_y_pred=[]\n",
    "    for j,model in enumerate(range(len(list_of_all_models))): # APPLIED ROOTS REQUIREMENTS 30\n",
    "        #print(j)\n",
    "        #print(list_selected_row[j]) # checking row sampling   \n",
    "        if i not in list_selected_row[j]: # definng the rows which are not in row sampling\n",
    "            #models_y_pred.append(model.predict(point[list_selected_columns[j]].reshape(1,-1))) # predicting with rows(which are not part of sampling) and column sampling\n",
    "            models_y_pred.append(list_of_all_models[j].predict(point[list_selected_columns[j]].reshape(1,-1))) # predicting with rows(which are not part of sampling) and column sampling\n",
    "            #print(models_y_pred)\n",
    "    y_pred.append(np.median((models_y_pred)))\n",
    "#print((y_pred))\n",
    "        \n",
    "OOB_SCORE=mean_squared_error(y,y_pred)\n",
    "print(\"OOB_SCORE: \",OOB_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceW5-D88Uswi"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred_ALL:  35\n",
      "len y_pred_All_oobs:  35\n"
     ]
    }
   ],
   "source": [
    "#TRYING TO ITERATE IT FOR 35 TIMES and MSE and OOBs calculation \n",
    "#20 MARCH 2022\n",
    "# APPLIED ROOTS REQUIREMENTS TO ITERATE 35 TIMES AND EACH ITERATION SHOULD HAVE 30 SAMPLES \n",
    "\n",
    "\n",
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "\n",
    "input_all=[]\n",
    "output_all=[]\n",
    "rows_all=[]\n",
    "columns_all=[]\n",
    "outer_model_All=[]\n",
    "y_pred_All=[]        # FOR ALL MSE PREDICTION \n",
    "y_pred_All_oobs=[]   # FOR ALL OOBS PREDICTION \n",
    "\n",
    "\n",
    "for k in range(35): # applied roots requirements 35 times \n",
    "    #print(\"\\n\\nk: \",k) #count \n",
    "    list_input_data =[]\n",
    "    list_output_data =[]\n",
    "    list_selected_row= []\n",
    "    list_selected_columns=[]\n",
    "    \n",
    "    inner_model=[]\n",
    "    #new_pred_y=[]\n",
    "    for i1 in range(0,30): # applied roots requirements 30 times \n",
    "        a,b,c,d=generating_samples(x,y) #generating samples of rows and columns \n",
    "        #print(a)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)\n",
    "        \n",
    "        #print(\"len of list_input_data: \",len(list_input_data))\n",
    "        #print(\"len of list_selected_columns: \",len(list_selected_columns))\n",
    "        \n",
    "        model=DecisionTreeRegressor(max_depth=None)\n",
    "        model=model.fit(list_input_data[i1],list_output_data[i1]) #fitting x,y \n",
    "        inner_model.append(model)\n",
    "        #print(\"inner_model: \",inner_model)\n",
    "        \n",
    "    input_all.append(list_input_data)\n",
    "    output_all.append(list_output_data)\n",
    "    rows_all.append(list_selected_row)\n",
    "    columns_all.append(list_selected_columns)\n",
    "    outer_model_All.append(inner_model)\n",
    "    #print(\"outer_model_All: \",outer_model_All) # outer_model_All\n",
    "    \n",
    "    \n",
    "    # MSE PREDICTION FOR ALL ITERATIONS\n",
    "    y_pred=[]\n",
    "    for datapoint in x: #boston data\n",
    "        array_y=[]\n",
    "        for i2 in range(len(list_of_all_models)): #applied roots requirement 30 times \n",
    "            array_y.append(outer_model_All[k][i2].predict(datapoint[columns_all[k][i2]].reshape(1,-1))) # each datapoint will have 30 predictions\n",
    "        y_pred.append(np.median(np.array(array_y).reshape(1,-1))) # take either mean/median\n",
    "    y_pred_All.append(y_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # OOBS PREDICTION FOR ALL ITERATIONS\n",
    "    y_pred_oobs=[]\n",
    "    #print(y_pred)\n",
    "    for i,point in enumerate (x): # boston data \n",
    "        #print(i)\n",
    "        #print(point)\n",
    "        #print(len(point))\n",
    "        models_y_pred_oobs=[]\n",
    "        for j,t in enumerate(range(len(list_of_all_models))): # APPLIED ROOTS REQUIREMENTS 30\n",
    "            #print(j)\n",
    "            #print(list_selected_row[j]) # checking row sampling   \n",
    "            if i not in rows_all[k][j]: # definng the rows which are not in row sampling\n",
    "                models_y_pred_oobs.append(outer_model_All[k][j].predict(point[columns_all[k][j]].reshape(1,-1))) # predicting with rows(which are not part of sampling) and column sampling\n",
    "                #print(models_y_pred)\n",
    "        y_pred_oobs.append(np.median((models_y_pred_oobs))) # take either mean/median\n",
    "    y_pred_All_oobs.append(y_pred_oobs)\n",
    "\n",
    "\n",
    "\n",
    "# PRINT OF  MSE PREDICTION FOR ALL ITERATIONS\n",
    "#print(\"y_pred_All: \",(y_pred_All))\n",
    "print(\"Y_pred_ALL: \",len(y_pred_All))\n",
    "\n",
    "\n",
    "# PRINT OF OOBS PREDICTION FOR ALL ITERATIONS\n",
    "#print(\"\\n\\ny_pred_All_oobs: \",y_pred_All_oobs)\n",
    "print(\"len y_pred_All_oobs: \", len(y_pred_All_oobs))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_ALL:  [0.022, 0.383, 0.052, 0.077, 0.028, 0.217, 0.082, 0.01, 0.033, 0.017, 0.239, 0.028, 0.097, 0.009, 0.008, 0.087, 0.057, 0.078, 0.387, 0.034, 0.201, 0.184, 0.032, 0.018, 0.132, 0.02, 0.244, 0.028, 0.035, 0.099, 0.031, 0.118, 0.237, 0.086, 0.064]\n",
      "\n",
      "\n",
      "len of MSE_ALL:  35\n"
     ]
    }
   ],
   "source": [
    "# MSE \n",
    "\n",
    "MSE_ALL=[]\n",
    "for i in range(len(input_all)):\n",
    "    MSE=np.round(mean_squared_error(y,y_pred_All[i]),3)\n",
    "    MSE_ALL.append(MSE)\n",
    "print(\"MSE_ALL: \",MSE_ALL)\n",
    "print(\"\\n\\nlen of MSE_ALL: \",len(MSE_ALL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOBS_ALL:  [14.518, 16.029, 12.456, 14.107, 13.175, 17.525, 18.485, 13.901, 14.137, 16.077, 12.393, 13.709, 13.42, 17.395, 14.803, 12.68, 14.378, 16.928, 15.213, 16.61, 14.452, 16.044, 15.4, 14.694, 15.284, 14.391, 14.768, 13.067, 15.446, 12.903, 13.851, 11.971, 14.841, 15.261, 14.397]\n",
      "\n",
      "\n",
      "len of OOBS_ALL:  35\n"
     ]
    }
   ],
   "source": [
    "#OOBS\n",
    "\n",
    "OOBS_ALL=[]\n",
    "for i in range(len(input_all)):\n",
    "    OOBS=np.round(mean_squared_error(y,y_pred_All_oobs[i]),3)\n",
    "    OOBS_ALL.append(OOBS)\n",
    "print(\"OOBS_ALL: \",OOBS_ALL)\n",
    "print(\"\\n\\nlen of OOBS_ALL: \", len(OOBS_ALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of n:  35\n",
      "\n",
      "\n",
      "MSE_sample_mean:  0.09925714285714285\n",
      "MSE_std:  0.0999526581815162\n",
      "MSE_CI:  [0.06546697712372945, 0.13304730859055625]\n",
      "\n",
      "\n",
      "OOBS_sample_mean:  14.70597142857143\n",
      "OOBS_std:  1.5193145162156758\n",
      "OOBS_CI:  [14.19234937751124, 15.219593479631621]\n"
     ]
    }
   ],
   "source": [
    "n=len(MSE_ALL)\n",
    "print(\"len of n: \", n)\n",
    "\n",
    "# MSE CI\n",
    "MSE_sample_mean=np.mean(MSE_ALL)\n",
    "MSE_std=np.std(MSE_ALL)\n",
    "MSE_CI= [MSE_sample_mean- 2*(MSE_std/np.sqrt(n)), MSE_sample_mean + 2*(MSE_std/np.sqrt(n))]\n",
    "print(\"\\n\\nMSE_sample_mean: \", MSE_sample_mean)\n",
    "print(\"MSE_std: \",MSE_std)\n",
    "print(\"MSE_CI: \", MSE_CI)\n",
    "\n",
    "\n",
    "#OOBS CI\n",
    "OOBS_sample_mean=np.mean(OOBS_ALL)\n",
    "OOBS_std=np.std(OOBS_ALL)\n",
    "OOBS_CI= [OOBS_sample_mean- 2*(OOBS_std/np.sqrt(n)), OOBS_sample_mean + 2*(OOBS_std/np.sqrt(n))]\n",
    "print(\"\\n\\nOOBS_sample_mean: \", OOBS_sample_mean)\n",
    "print(\"OOBS_std: \", OOBS_std)\n",
    "print(\"OOBS_CI: \", OOBS_CI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [],
   "source": [
    "xq= np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(xq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_of_all_models:  [DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "\n",
      "len of list_of_all_models:  30\n"
     ]
    }
   ],
   "source": [
    "# TASK 3  EXECUTION CAN BE DONE ONLY AFER EXCEUTING TASK 1\n",
    "#\n",
    "\n",
    "list_of_all_models=[]\n",
    "\n",
    "for t,(X,Y) in enumerate (zip(list_input_data, list_output_data)): # Applied Roots requirements is 30 iterations \n",
    "    #print(t) # checking the length # applied roots requirements 30 iterations\n",
    "    #print(X[0]) \n",
    "    #print(\"len X: \",len(X)) # each iteration will have the length of 506 rows\n",
    "    \n",
    "    #print(X) \n",
    "    #print(Y)\n",
    "    #print(\"len Y: \",len(Y))\n",
    "    \n",
    "\n",
    "    model=DecisionTreeRegressor(max_depth=None)\n",
    "    model=model.fit(X,Y)\n",
    "    #print(model) # checking the length of the model. Applied Roots requirements is 30 iterations \n",
    "    list_of_all_models.append(model)\n",
    "\n",
    "print(\"list_of_all_models: \",list_of_all_models)\n",
    "print(\"\\n\\n\\nlen of list_of_all_models: \", len(list_of_all_models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query data point:  [1.8000e-01 2.0000e+01 5.0000e+00 0.0000e+00 4.2100e-01 5.6000e+00\n",
      " 7.2200e+01 7.9500e+00 7.0000e+00 3.0000e+01 1.9100e+01 3.7213e+02\n",
      " 1.8600e+01]\n",
      "\n",
      "y_pred: \n",
      " [18.7]\n",
      "\n",
      "len y_pred:  1\n"
     ]
    }
   ],
   "source": [
    "Y_pred=[] # creating a list to take the median value from the array_of_Y\n",
    "print(\"query data point: \",xq) # query point \n",
    "array_of_Y=[] \n",
    "\n",
    "for i in range(len(list_of_all_models)):\n",
    "    array_of_Y.append(list_of_all_models[i].predict(xq[list_selected_columns[i]].reshape(1,-1))) # simple understanding purpose only {model.predict(x)} \n",
    "Y_pred.append(np.median(np.array(array_of_Y).reshape(1,-1))) #take mean / median\n",
    "\n",
    "y_pred=np.array(Y_pred)\n",
    "print(\"\\ny_pred: \\n\",y_pred)\n",
    "print(\"\\nlen y_pred: \",len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJHTGEZgWJjR"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOdUi-0xWOJ9"
   },
   "source": [
    "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIcax45hWKT-"
   },
   "source": [
    "### TASK 1: \n",
    "1. In task 1 after doing the row sampling and the column sampling, boston data has been substituted. For each row of boston data, there are 30 predictions has been done.\n",
    "2. From the 30 predictions, median has been considered and predicted the value.\n",
    "3. As, each row has one predicted value. So, MSE has been calculated by substuting boston data from predicted value.\n",
    "4. While OOBS calculated, based on left over rows (which are not part of row sampling) and predicted values. \n",
    "\n",
    "## TASK 2.\n",
    "1. Similar like task 1, in this 35 iterations has been done and each iteraion will have the 30 predictions. From this 30 predictions, median/mean has been calculated.\n",
    "2. Once, 35 iteration has been done, so the MSE will have the values, as same way OOBS will have the 25 values. \n",
    "3. Based on 35 values, CI has been calculated for the task 2.\n",
    "\n",
    "## TASK 3.\n",
    "1. In this, query point(xq) substitued and found the preidicted value.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
